#!/usr/bin/env python3
"""–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–∑–±–∏–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π"""

def split_long_message(text: str, max_length: int = 4096):
    """–ö–æ–ø–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–∑–±–∏–≤–∫–∏ –∏–∑ bot.py –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    if len(text) <= max_length:
        return [text]
    
    parts = []
    current_part = ""
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º (–¥–≤–æ–π–Ω–æ–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏)
    paragraphs = text.split('\n\n')
    
    for paragraph in paragraphs:
        # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–±–∑–∞—Ü–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏–º–∏—Ç
        if len(current_part) + len(paragraph) + 2 > max_length:
            if current_part:  # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                parts.append(current_part.strip())
                current_part = paragraph + '\n\n'
            else:  # –ï—Å–ª–∏ –∞–±–∑–∞—Ü —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
                sentences = paragraph.split('. ')
                for sentence in sentences:
                    if len(current_part) + len(sentence) + 2 > max_length:
                        if current_part:
                            parts.append(current_part.strip())
                            current_part = sentence + '. '
                        else:  # –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º
                            while len(sentence) > max_length:
                                parts.append(sentence[:max_length])
                                sentence = sentence[max_length:]
                            current_part = sentence + '. '
                    else:
                        current_part += sentence + '. '
                current_part += '\n\n'
        else:
            current_part += paragraph + '\n\n'
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å
    if current_part.strip():
        parts.append(current_part.strip())
    
    return parts

def test_splitting():
    # –°–æ–∑–¥–∞–µ–º –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    long_text = """
**üìñ –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö 1C —Å –ò–ò**

_–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –Ω–µ–æ–±—ã—á–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ –±—É—Ö–≥–∞–ª—Ç–µ—Ä–∏–∏ 1C._

‚è±Ô∏è **–í—Ä–µ–º—è –∏–∑—É—á–µ–Ω–∏—è:** 1-2 –¥–Ω—è
üìä **–°–ª–æ–∂–Ω–æ—Å—Ç—å:** –°—Ä–µ–¥–Ω–∏–π

**üìö –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è:**

**–ö—Ä–∞—Ç–∫–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ –≤ —Ç–µ–º—É**
–î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö 1C —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ò–ò ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥ –≤—ã—è–≤–ª–µ–Ω–∏—è –Ω–µ–æ–±—ã—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è—Ö. """ + "–ê" * 1500 + """

**–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –≤–∫–ª—é—á–∞—é—Ç:**
- **–¢–æ—á–µ—á–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏** - –æ–¥–∏–Ω–æ—á–Ω—ã–µ –≤—ã–±—Ä–æ—Å—ã
- **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏** - –∞–Ω–æ–º–∞–ª–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å–ª–æ–≤–∏–π
- **–ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏** - –≥—Ä—É–ø–ø–æ–≤—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è

**–ü–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω –∏–∑—É—á–µ–Ω–∏—è (1-3 –¥–Ω—è):**
1. **–î–µ–Ω—å 1: –û—Å–Ω–æ–≤—ã** - –∏–∑—É—á–µ–Ω–∏–µ —Ç–µ–æ—Ä–∏–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π
2. **–î–µ–Ω—å 2: –ü—Ä–∞–∫—Ç–∏–∫–∞** - —Ä–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ 1C
3. **–î–µ–Ω—å 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è** - —Å–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è

**üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏:**
‚Ä¢ **–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** [scikit-learn: IsolationForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)
‚Ä¢ **GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏:** [Anomaly Detection Resources](https://github.com/yzhao062/anomaly-detection-resources)
‚Ä¢ **–°—Ç–∞—Ç—å–∏:** [–î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π —Å Python](https://habr.com/ru/articles/338306/)

**üé• –í–∏–¥–µ–æ –∏ –∫—É—Ä—Å—ã:**
‚Ä¢ **YouTube –≤–∏–¥–µ–æ:** [Data Science - Isolation Forest](https://www.youtube.com/watch?v=O9WLaT3rWEw)
‚Ä¢ **–û–Ω–ª–∞–π–Ω –∫—É—Ä—Å—ã:** [Coursera - Machine Learning](https://www.coursera.org/learn/machine-learning)

**üí° –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã:**

**–ü—Ä–∏–º–µ—Ä 1: –ë–∞–∑–æ–≤–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —Å Isolation Forest**

```python
import pandas as pd
from sklearn.ensemble import IsolationForest

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV (—ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑ 1C)
data = pd.read_csv('transactions.csv')
features = data[['amount']]

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = IsolationForest(contamination=0.01, random_state=42)
model.fit(features)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π
data['anomaly'] = model.predict(features)
anomalies = data[data['anomaly'] == -1]
print("–ê–Ω–æ–º–∞–ª–∏–∏:", anomalies)
```

–≠—Ç–æ—Ç –∫–æ–¥ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º Isolation Forest –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π. """ + "–ë" * 2000 + """

**–ü—Ä–∏–º–µ—Ä 2: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å 1C —á–µ—Ä–µ–∑ ODBC**

–î–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ 1C –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ ODBC –¥—Ä–∞–π–≤–µ—Ä –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫—É pyodbc –¥–ª—è –ø—Ä—è–º–æ–≥–æ —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.
    """
    
    print(f"üìè –î–ª–∏–Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {len(long_text)} —Å–∏–º–≤–æ–ª–æ–≤")
    print("üìè –õ–∏–º–∏—Ç Telegram: 4096 —Å–∏–º–≤–æ–ª–æ–≤")
    print("=" * 50)
    
    parts = split_long_message(long_text)
    
    print(f"üî¢ –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(parts)} —á–∞—Å—Ç–µ–π:")
    total_length = 0
    for i, part in enumerate(parts, 1):
        total_length += len(part)
        status = "‚úÖ –í –ø—Ä–µ–¥–µ–ª–∞—Ö –ª–∏–º–∏—Ç–∞" if len(part) <= 4096 else "‚ùå –ü–†–ï–í–´–®–ï–ù –õ–ò–ú–ò–¢!"
        print(f"  –ß–∞—Å—Ç—å {i}: {len(part)} —Å–∏–º–≤–æ–ª–æ–≤ - {status}")
    
    print(f"\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞: –∏—Å—Ö–æ–¥–Ω–∞—è –¥–ª–∏–Ω–∞ {len(long_text)} = —Å—É–º–º–∞ —á–∞—Å—Ç–µ–π {total_length}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞—á–∞–ª–æ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏
    print("\nüìù –ù–∞—á–∞–ª–æ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏:")
    for i, part in enumerate(parts, 1):
        lines = part.strip().split('\n')[:3]  # –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏
        preview = ' | '.join(line.strip() for line in lines if line.strip())
        print(f"  –ß–∞—Å—Ç—å {i}: {preview[:100]}...")

if __name__ == '__main__':
    test_splitting()
